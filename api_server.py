"""
YOLO11 åç«¯ API æœåŠ¡
ä½¿ç”¨ FastAPI æä¾› RESTful API æ¥å£
"""

import io
import base64
import uuid
from pathlib import Path
from typing import Optional, List

import cv2
import numpy as np
from PIL import Image
from fastapi import FastAPI, File, UploadFile, HTTPException, Form, Body, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel
import logging
import json
import os

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
from ultralytics import YOLO

# è…¾è®¯äº‘ SDK
try:
    from tencentcloud.common import credential
    from tencentcloud.common.profile.client_profile import ClientProfile
    from tencentcloud.common.profile.http_profile import HttpProfile
    from tencentcloud.tiia.v20190529 import tiia_client, models as tiia_models
    TENCENT_CLOUD_AVAILABLE = True
except ImportError:
    TENCENT_CLOUD_AVAILABLE = False
    logger.warning("è…¾è®¯äº‘ SDK æœªå®‰è£…ï¼Œäº‘ç«¯ API åŠŸèƒ½ä¸å¯ç”¨")

# HyperLPR3 è½¦ç‰Œè¯†åˆ«
try:
    import hyperlpr3 as lpr3
    HYPERLPR_AVAILABLE = True
    # åˆå§‹åŒ–è½¦ç‰Œè¯†åˆ«å™¨ï¼ˆä½¿ç”¨è½»é‡çº§æ¨¡å‹ï¼Œé€‚åˆCPUï¼‰
    lpr_model = lpr3.LicensePlateCatcher()
    logger.info("HyperLPR3 è½¦ç‰Œè¯†åˆ«æ¨¡å—å·²åŠ è½½")
except ImportError:
    HYPERLPR_AVAILABLE = False
    lpr_model = None
    logger.warning("HyperLPR3 æœªå®‰è£…ï¼Œè½¦ç‰Œè¯†åˆ«åŠŸèƒ½ä¸å¯ç”¨")
except Exception as e:
    HYPERLPR_AVAILABLE = False
    lpr_model = None
    logger.warning(f"HyperLPR3 åˆå§‹åŒ–å¤±è´¥: {e}")

# ç™¾åº¦ AI å¼€æ”¾å¹³å°
try:
    from aip import AipImageClassify, AipBodyAnalysis, AipFace
    BAIDU_AI_AVAILABLE = True
    logger.info("ç™¾åº¦ AI SDK å·²åŠ è½½")
except ImportError:
    BAIDU_AI_AVAILABLE = False
    logger.warning("ç™¾åº¦ AI SDK æœªå®‰è£…ï¼Œè¯·å®‰è£…ï¼špip install baidu-aip")


# ==================== FastAPI åº”ç”¨åˆå§‹åŒ– ====================
app = FastAPI(
    title="YOLO11 è§†è§‰è¯†åˆ« API",
    description="æä¾›å›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€ç›®æ ‡è·Ÿè¸ªã€å§¿æ€ä¼°è®¡ç­‰åŠŸèƒ½",
    version="1.0.0"
)

# é…ç½® CORSï¼ˆå…è®¸ç§»åŠ¨ç«¯è·¨åŸŸè®¿é—®ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ==================== è¯·æ±‚ä½“æ¨¡å‹ï¼ˆç”¨äº JSON è¯·æ±‚ï¼‰ ====================
class DetectRequest(BaseModel):
    """ç›®æ ‡æ£€æµ‹è¯·æ±‚æ¨¡å‹"""
    image_base64: str
    conf: float = 0.25
    iou: float = 0.45
    return_image: bool = True


class ClassifyRequest(BaseModel):
    """å›¾åƒåˆ†ç±»è¯·æ±‚æ¨¡å‹"""
    image_base64: str
    conf: float = 0.25
    top_k: int = 5
    analyze_scene: bool = True  # æ˜¯å¦åˆ†æåœºæ™¯ç±»å‹


class PoseRequest(BaseModel):
    """å§¿æ€ä¼°è®¡è¯·æ±‚æ¨¡å‹"""
    image_base64: str
    conf: float = 0.25
    iou: float = 0.45
    return_image: bool = True


class SegmentRequest(BaseModel):
    """å®ä¾‹åˆ†å‰²è¯·æ±‚æ¨¡å‹"""
    image_base64: str
    conf: float = 0.25
    iou: float = 0.45
    return_image: bool = True


class TencentCloudRequest(BaseModel):
    """è…¾è®¯äº‘å›¾åƒåˆ†æè¯·æ±‚æ¨¡å‹"""
    image_base64: str
    api_type: str = "detect"  # detect: ç›®æ ‡æ£€æµ‹, label: å›¾åƒæ ‡ç­¾, car: è½¦è¾†è¯†åˆ«


class LPRRequest(BaseModel):
    """è½¦ç‰Œè¯†åˆ«è¯·æ±‚æ¨¡å‹"""
    image_base64: str
    return_image: bool = True


class BaiduAIRequest(BaseModel):
    """ç™¾åº¦ AI è¯·æ±‚æ¨¡å‹"""
    image_base64: str
    api_type: str = "classify"  # classify: å›¾åƒåˆ†ç±», detect: ç‰©ä½“æ£€æµ‹, face: äººè„¸è¯†åˆ«


# ==================== ç™¾åº¦ AI é…ç½® ====================
class BaiduAIConfig:
    """ç™¾åº¦ AI é…ç½®ç®¡ç†"""
    
    @classmethod
    def get_app_id(cls) -> str:
        """åŠ¨æ€è·å– APP_ID"""
        return os.environ.get("BAIDU_APP_ID", "")
    
    @classmethod
    def get_api_key(cls) -> str:
        """åŠ¨æ€è·å– API_KEY"""
        return os.environ.get("BAIDU_API_KEY", "")
    
    @classmethod
    def get_secret_key(cls) -> str:
        """åŠ¨æ€è·å– SECRET_KEY"""
        return os.environ.get("BAIDU_SECRET_KEY", "")
    
    @classmethod
    def is_configured(cls) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²é…ç½®"""
        return bool(cls.get_app_id() and cls.get_api_key() and cls.get_secret_key())
    
    @classmethod
    def get_image_client(cls):
        """è·å–ç™¾åº¦å›¾åƒè¯†åˆ«å®¢æˆ·ç«¯"""
        if not BAIDU_AI_AVAILABLE:
            raise HTTPException(status_code=500, detail="ç™¾åº¦ AI SDK æœªå®‰è£…")
        if not cls.is_configured():
            raise HTTPException(status_code=500, detail="ç™¾åº¦ AI å¯†é’¥æœªé…ç½®ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ BAIDU_APP_ID, BAIDU_API_KEY å’Œ BAIDU_SECRET_KEY")
        return AipImageClassify(cls.get_app_id(), cls.get_api_key(), cls.get_secret_key())
    
    @classmethod
    def get_face_client(cls):
        """è·å–ç™¾åº¦äººè„¸è¯†åˆ«å®¢æˆ·ç«¯"""
        if not BAIDU_AI_AVAILABLE:
            raise HTTPException(status_code=500, detail="ç™¾åº¦ AI SDK æœªå®‰è£…")
        if not cls.is_configured():
            raise HTTPException(status_code=500, detail="ç™¾åº¦ AI å¯†é’¥æœªé…ç½®")
        return AipFace(cls.get_app_id(), cls.get_api_key(), cls.get_secret_key())


# ==================== è…¾è®¯äº‘é…ç½® ====================
class TencentCloudConfig:
    """è…¾è®¯äº‘é…ç½®ç®¡ç†"""
    # ä»ç¯å¢ƒå˜é‡è¯»å–å¯†é’¥ï¼ˆå®‰å…¨æ–¹å¼ï¼‰
    SECRET_ID = os.environ.get("TENCENT_SECRET_ID", "")
    SECRET_KEY = os.environ.get("TENCENT_SECRET_KEY", "")
    REGION = os.environ.get("TENCENT_REGION", "ap-guangzhou")
    
    @classmethod
    def is_configured(cls) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²é…ç½®"""
        return bool(cls.SECRET_ID and cls.SECRET_KEY)
    
    @classmethod
    def get_client(cls):
        """è·å–è…¾è®¯äº‘å›¾åƒåˆ†æå®¢æˆ·ç«¯"""
        if not TENCENT_CLOUD_AVAILABLE:
            raise HTTPException(status_code=500, detail="è…¾è®¯äº‘ SDK æœªå®‰è£…")
        if not cls.is_configured():
            raise HTTPException(status_code=500, detail="è…¾è®¯äº‘å¯†é’¥æœªé…ç½®ï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ TENCENT_SECRET_ID å’Œ TENCENT_SECRET_KEY")
        
        cred = credential.Credential(cls.SECRET_ID, cls.SECRET_KEY)
        httpProfile = HttpProfile()
        httpProfile.endpoint = "tiia.tencentcloudapi.com"
        clientProfile = ClientProfile()
        clientProfile.httpProfile = httpProfile
        client = tiia_client.TiiaClient(cred, cls.REGION, clientProfile)
        return client


# ==================== æ¨¡å‹ç®¡ç† ====================
class ModelManager:
    """æ¨¡å‹ç®¡ç†å™¨ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    _instance = None
    _models = {}
    
    MODEL_PATHS = {
        'detect': 'yolo11n.pt',
        'classify': 'yolo11n-cls.pt',
        'pose': 'yolo11n-pose.pt',
        'segment': 'yolo11n-seg.pt',
    }
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def get_model(self, task: str) -> YOLO:
        """è·å–æŒ‡å®šä»»åŠ¡çš„æ¨¡å‹"""
        if task not in self._models:
            model_path = self.MODEL_PATHS.get(task)
            if model_path is None:
                raise ValueError(f"ä¸æ”¯æŒçš„ä»»åŠ¡ç±»å‹: {task}")
            print(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_path}")
            self._models[task] = YOLO(model_path)
        return self._models[task]


model_manager = ModelManager()


# ==================== åœºæ™¯åˆ†ç±»æ˜ å°„ ====================
class SceneAnalyzer:
    """åœºæ™¯åˆ†æå™¨ï¼šå°†ä½çº§åˆ†ç±»æ˜ å°„åˆ°é«˜çº§åœºæ™¯ç±»åˆ«"""
    
    # åœºæ™¯ç±»å‹å®šä¹‰
    SCENE_TYPES = {
        "portrait": {
            "name": "äººç‰©ç…§ç‰‡",
            "icon": "ğŸ‘¤",
            "description": "åŒ…å«äººç‰©çš„ç…§ç‰‡",
            "keywords": ["person", "face", "portrait", "people", "human", "man", "woman", "child", "baby"]
        },
        "animal": {
            "name": "åŠ¨ç‰©",
            "icon": "ğŸ¾",
            "description": "åŠ¨ç‰©ç…§ç‰‡",
            "keywords": ["dog", "cat", "bird", "fish", "horse", "elephant", "bear", "zebra", "giraffe", "cow", "sheep", "tiger", "lion", "monkey", "rabbit", "hamster", "pet"]
        },
        "cityscape": {
            "name": "åŸå¸‚é£æ™¯",
            "icon": "ğŸ™ï¸",
            "description": "åŸå¸‚å»ºç­‘å’Œè¡—æ™¯",
            "keywords": ["skyscraper", "building", "tower", "bridge", "street", "road", "traffic", "car", "bus", "train", "architecture", "city", "urban", "downtown", "office"]
        },
        "nature": {
            "name": "è‡ªç„¶é£æ™¯",
            "icon": "ğŸï¸",
            "description": "è‡ªç„¶é£å…‰å’Œæˆ·å¤–åœºæ™¯",
            "keywords": ["mountain", "lake", "river", "ocean", "sea", "beach", "forest", "tree", "flower", "garden", "sky", "cloud", "sunset", "sunrise", "landscape", "grass", "field", "valley"]
        },
        "food": {
            "name": "ç¾é£Ÿ",
            "icon": "ğŸ½ï¸",
            "description": "é£Ÿç‰©å’Œé¥®å“",
            "keywords": ["food", "pizza", "burger", "cake", "fruit", "vegetable", "bread", "coffee", "drink", "meal", "dinner", "breakfast", "lunch", "restaurant", "dish", "cuisine"]
        },
        "vehicle": {
            "name": "äº¤é€šå·¥å…·",
            "icon": "ğŸš—",
            "description": "è½¦è¾†å’Œäº¤é€šå·¥å…·",
            "keywords": ["car", "truck", "bus", "motorcycle", "bicycle", "airplane", "boat", "ship", "train", "vehicle", "automobile", "van"]
        },
        "indoor": {
            "name": "å®¤å†…åœºæ™¯",
            "icon": "ğŸ ",
            "description": "å®¤å†…ç¯å¢ƒå’Œå®¶å±…",
            "keywords": ["room", "furniture", "sofa", "chair", "table", "bed", "lamp", "desk", "kitchen", "bathroom", "bedroom", "living", "office", "interior"]
        },
        "sports": {
            "name": "è¿åŠ¨",
            "icon": "âš½",
            "description": "ä½“è‚²è¿åŠ¨ç›¸å…³",
            "keywords": ["ball", "football", "basketball", "tennis", "golf", "baseball", "soccer", "swimming", "running", "sport", "gym", "stadium", "athlete"]
        },
        "electronics": {
            "name": "ç”µå­è®¾å¤‡",
            "icon": "ğŸ“±",
            "description": "ç”µå­äº§å“å’Œè®¾å¤‡",
            "keywords": ["phone", "computer", "laptop", "keyboard", "mouse", "screen", "monitor", "television", "camera", "electronic", "device", "gadget"]
        },
        "art": {
            "name": "è‰ºæœ¯/åŠ¨æ¼«",
            "icon": "ğŸ¨",
            "description": "è‰ºæœ¯ä½œå“ã€æ’ç”»æˆ–åŠ¨æ¼«é£æ ¼",
            "keywords": ["painting", "art", "drawing", "illustration", "cartoon", "comic", "animation", "poster", "design", "graphic"]
        },
        "text": {
            "name": "æ–‡æœ¬/æ–‡æ¡£",
            "icon": "ğŸ“„",
            "description": "åŒ…å«æ–‡å­—çš„å›¾ç‰‡",
            "keywords": ["document", "paper", "book", "newspaper", "magazine", "text", "letter", "sign", "poster", "menu", "envelope", "notebook"]
        },
        "unknown": {
            "name": "å…¶ä»–",
            "icon": "â“",
            "description": "æ— æ³•ç¡®å®šçš„åœºæ™¯ç±»å‹",
            "keywords": []
        }
    }
    
    # å›¾åƒç‰¹å¾åˆ†æé˜ˆå€¼
    COLOR_THRESHOLDS = {
        "anime_saturation": 0.6,  # åŠ¨æ¼«é€šå¸¸è‰²å½©é¥±å’Œåº¦é«˜
        "anime_edge_ratio": 0.15,  # åŠ¨æ¼«è¾¹ç¼˜æ¸…æ™°
    }
    
    @classmethod
    def analyze_image_features(cls, image: np.ndarray) -> dict:
        """åˆ†æå›¾åƒç‰¹å¾"""
        features = {}
        
        # è½¬æ¢åˆ°HSVé¢œè‰²ç©ºé—´
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        
        # è®¡ç®—é¥±å’Œåº¦å‡å€¼ï¼ˆåŠ¨æ¼«å›¾ç‰‡é€šå¸¸é¥±å’Œåº¦è¾ƒé«˜ï¼‰
        saturation = hsv[:, :, 1].mean() / 255.0
        features["saturation"] = saturation
        
        # è®¡ç®—é¢œè‰²ä¸°å¯Œåº¦ï¼ˆé€šè¿‡ç›´æ–¹å›¾ï¼‰
        hist_h = cv2.calcHist([hsv], [0], None, [180], [0, 180])
        hist_h = hist_h / hist_h.sum()  # å½’ä¸€åŒ–
        color_variety = (hist_h > 0.01).sum() / 180.0
        features["color_variety"] = float(color_variety)
        
        # è¾¹ç¼˜æ£€æµ‹ï¼ˆåŠ¨æ¼«å›¾ç‰‡è¾¹ç¼˜é€šå¸¸æ›´æ¸…æ™°ï¼‰
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 100, 200)
        edge_ratio = edges.mean() / 255.0
        features["edge_ratio"] = edge_ratio
        
        # é¢œè‰²æ•°é‡ï¼ˆåŠ¨æ¼«å›¾ç‰‡é¢œè‰²æ•°é‡ç›¸å¯¹è¾ƒå°‘ä½†è¾¹ç•Œæ¸…æ™°ï¼‰
        # ç®€åŒ–é¢œè‰²
        small = cv2.resize(image, (64, 64))
        small = (small // 32) * 32  # é‡åŒ–é¢œè‰²
        unique_colors = len(np.unique(small.reshape(-1, 3), axis=0))
        features["unique_colors"] = unique_colors
        
        # åˆ¤æ–­æ˜¯å¦å¯èƒ½æ˜¯åŠ¨æ¼«/å¡é€šé£æ ¼
        is_anime_style = (
            saturation > cls.COLOR_THRESHOLDS["anime_saturation"] and
            edge_ratio > cls.COLOR_THRESHOLDS["anime_edge_ratio"] and
            unique_colors < 500  # åŠ¨æ¼«é€šå¸¸é¢œè‰²æ•°é‡æœ‰é™
        )
        features["is_anime_style"] = bool(is_anime_style)  # è½¬æ¢ä¸º Python åŸç”Ÿ bool
        
        # è®¡ç®—äº®åº¦ï¼ˆç”¨äºåˆ¤æ–­å®¤å†…å¤–ï¼‰
        brightness = hsv[:, :, 2].mean() / 255.0
        features["brightness"] = float(brightness)  # è½¬æ¢ä¸º Python åŸç”Ÿ float
        features["saturation"] = float(saturation)  # ç¡®ä¿æ˜¯ Python åŸç”Ÿ float
        features["edge_ratio"] = float(edge_ratio)  # ç¡®ä¿æ˜¯ Python åŸç”Ÿ float
        
        return features
    
    @classmethod
    def classify_scene(cls, classifications: list, image_features: dict = None, detected_objects: list = None) -> dict:
        """æ ¹æ®åˆ†ç±»ç»“æœæ¨æ–­åœºæ™¯ç±»å‹"""
        
        scene_scores = {scene: 0.0 for scene in cls.SCENE_TYPES.keys()}
        matched_keywords = []
        
        # åˆ†æåˆ†ç±»ç»“æœ
        for item in classifications:
            class_name = item["class_name"].lower()
            confidence = item["confidence"]
            
            for scene_type, scene_info in cls.SCENE_TYPES.items():
                for keyword in scene_info["keywords"]:
                    if keyword in class_name or class_name in keyword:
                        scene_scores[scene_type] += confidence
                        matched_keywords.append({
                            "keyword": keyword,
                            "class": class_name,
                            "scene": scene_type,
                            "confidence": confidence
                        })
        
        # åˆ†ææ£€æµ‹åˆ°çš„å¯¹è±¡ï¼ˆå¦‚æœæœ‰ï¼‰
        if detected_objects:
            for obj in detected_objects:
                obj_name = obj["class_name"].lower()
                obj_conf = obj["confidence"]
                
                # äººç‰©æ£€æµ‹æƒé‡æ›´é«˜
                if obj_name == "person":
                    scene_scores["portrait"] += obj_conf * 1.5
                
                for scene_type, scene_info in cls.SCENE_TYPES.items():
                    for keyword in scene_info["keywords"]:
                        if keyword in obj_name:
                            scene_scores[scene_type] += obj_conf * 0.8
        
        # å›¾åƒç‰¹å¾åˆ†æåŠ æˆ
        if image_features:
            # åŠ¨æ¼«/å¡é€šé£æ ¼æ£€æµ‹
            if image_features.get("is_anime_style", False):
                scene_scores["art"] += 0.5
            
            # é«˜é¥±å’Œåº¦å¯èƒ½æ˜¯é£Ÿç‰©æˆ–è‰ºæœ¯
            if image_features.get("saturation", 0) > 0.5:
                scene_scores["food"] += 0.1
                scene_scores["art"] += 0.1
        
        # æ‰¾å‡ºå¾—åˆ†æœ€é«˜çš„åœºæ™¯
        best_scene = max(scene_scores, key=scene_scores.get)
        best_score = scene_scores[best_scene]
        
        # å¦‚æœæœ€é«˜åˆ†å¤ªä½ï¼Œæ ‡è®°ä¸ºæœªçŸ¥
        if best_score < 0.1:
            best_scene = "unknown"
        
        scene_info = cls.SCENE_TYPES[best_scene]
        
        # è®¡ç®—æ‰€æœ‰åœºæ™¯çš„ç½®ä¿¡åº¦åˆ†å¸ƒ
        total_score = sum(scene_scores.values()) + 0.001  # é¿å…é™¤é›¶
        scene_distribution = [
            {
                "type": scene,
                "name": cls.SCENE_TYPES[scene]["name"],
                "icon": cls.SCENE_TYPES[scene]["icon"],
                "confidence": score / total_score
            }
            for scene, score in sorted(scene_scores.items(), key=lambda x: -x[1])
            if score > 0
        ][:5]  # åªè¿”å›å‰5ä¸ª
        
        return {
            "primary_scene": {
                "type": best_scene,
                "name": scene_info["name"],
                "icon": scene_info["icon"],
                "description": scene_info["description"],
                "confidence": min(best_score, 1.0)
            },
            "scene_distribution": scene_distribution,
            "matched_keywords": matched_keywords[:10],  # æœ€å¤šè¿”å›10ä¸ªåŒ¹é…å…³é”®è¯
            "image_features": {
                "is_anime_style": bool(image_features.get("is_anime_style", False)) if image_features else False,
                "saturation": float(round(image_features.get("saturation", 0), 2)) if image_features else 0.0,
                "brightness": float(round(image_features.get("brightness", 0), 2)) if image_features else 0.0,
            }
        }


scene_analyzer = SceneAnalyzer()


# ==================== å“åº”æ¨¡å‹ ====================
class BBox(BaseModel):
    x1: float
    y1: float
    x2: float
    y2: float


class DetectionResult(BaseModel):
    class_id: int
    class_name: str
    confidence: float
    bbox: BBox


class ClassificationResult(BaseModel):
    class_id: int
    class_name: str
    confidence: float


class Keypoint(BaseModel):
    name: str
    x: float
    y: float
    confidence: float


class PoseResult(BaseModel):
    person_id: int
    bbox: Optional[BBox]
    keypoints: List[Keypoint]


class APIResponse(BaseModel):
    success: bool
    task: str
    message: str
    data: Optional[dict] = None


# ==================== å·¥å…·å‡½æ•° ====================
def read_image_from_upload(file: UploadFile) -> np.ndarray:
    """ä»ä¸Šä¼ æ–‡ä»¶è¯»å–å›¾åƒ"""
    contents = file.file.read()
    nparr = np.frombuffer(contents, np.uint8)
    image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    if image is None:
        raise HTTPException(status_code=400, detail="æ— æ³•è§£æå›¾åƒæ–‡ä»¶")
    return image


def read_image_from_base64(base64_str: str) -> np.ndarray:
    """ä» Base64 å­—ç¬¦ä¸²è¯»å–å›¾åƒ"""
    try:
        if not base64_str or len(base64_str) < 100:
            raise HTTPException(status_code=400, detail=f"Base64 æ•°æ®å¤ªçŸ­æˆ–ä¸ºç©ºï¼Œé•¿åº¦: {len(base64_str) if base64_str else 0}")
        
        logger.info(f"æ¥æ”¶åˆ° Base64 æ•°æ®ï¼Œé•¿åº¦: {len(base64_str)}")
        
        # ç§»é™¤å¯èƒ½çš„ data URL å‰ç¼€
        if ',' in base64_str:
            base64_str = base64_str.split(',')[1]
        
        # ç§»é™¤å¯èƒ½çš„ç©ºç™½å­—ç¬¦
        base64_str = base64_str.strip()
        
        image_bytes = base64.b64decode(base64_str)
        logger.info(f"è§£ç åå›¾åƒå­—èŠ‚æ•°: {len(image_bytes)}")
        
        nparr = np.frombuffer(image_bytes, np.uint8)
        image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if image is None:
            raise HTTPException(status_code=400, detail="æ— æ³•è§£æ Base64 å›¾åƒï¼Œå¯èƒ½æ˜¯æ ¼å¼ä¸æ”¯æŒ")
        
        logger.info(f"å›¾åƒå°ºå¯¸: {image.shape}")
        return image
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Base64 è§£ç å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=400, detail=f"Base64 è§£ç å¤±è´¥: {str(e)}")


def encode_image_to_base64(image: np.ndarray, format: str = 'jpg') -> str:
    """å°†å›¾åƒç¼–ç ä¸º Base64"""
    if format == 'jpg':
        _, buffer = cv2.imencode('.jpg', image, [cv2.IMWRITE_JPEG_QUALITY, 85])
    else:
        _, buffer = cv2.imencode('.png', image)
    return base64.b64encode(buffer).decode('utf-8')


# ==================== API è·¯ç”± ====================

@app.get("/")
async def root():
    """API æ ¹è·¯ç”±"""
    return {
        "name": "YOLO11 è§†è§‰è¯†åˆ« API",
        "version": "1.0.0",
        "endpoints": {
            "detect": "/api/detect",
            "classify": "/api/classify",
            "pose": "/api/pose",
            "segment": "/api/segment"
        }
    }


@app.get("/api/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy", "message": "æœåŠ¡è¿è¡Œæ­£å¸¸"}


# ==================== ç›®æ ‡æ£€æµ‹ API ====================
@app.post("/api/detect")
async def detect_objects(request: DetectRequest):
    """
    ç›®æ ‡æ£€æµ‹ APIï¼ˆJSON è¯·æ±‚ï¼‰
    
    - image_base64: Base64 ç¼–ç çš„å›¾åƒ
    - conf: ç½®ä¿¡åº¦é˜ˆå€¼
    - iou: IoU é˜ˆå€¼
    - return_image: æ˜¯å¦è¿”å›æ ‡æ³¨åçš„å›¾åƒ
    """
    try:
        logger.info(f"[Detect] æ”¶åˆ° JSON è¯·æ±‚ï¼Œæ•°æ®é•¿åº¦: {len(request.image_base64)}")
        
        # è¯»å–å›¾åƒ
        image = read_image_from_base64(request.image_base64)
        
        # æ‰§è¡Œæ£€æµ‹
        model = model_manager.get_model('detect')
        results = model(image, conf=request.conf, iou=request.iou)
        
        # è§£æç»“æœ
        detections = []
        for result in results:
            boxes = result.boxes
            if boxes is not None:
                for box in boxes:
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    detections.append({
                        "class_id": int(box.cls[0]),
                        "class_name": result.names[int(box.cls[0])],
                        "confidence": float(box.conf[0]),
                        "bbox": {
                            "x1": float(x1),
                            "y1": float(y1),
                            "x2": float(x2),
                            "y2": float(y2)
                        }
                    })
        
        response_data = {
            "success": True,
            "task": "detection",
            "message": f"æ£€æµ‹åˆ° {len(detections)} ä¸ªç›®æ ‡",
            "data": {
                "detections": detections,
                "count": len(detections)
            }
        }
        
        # è¿”å›æ ‡æ³¨å›¾åƒ
        if request.return_image:
            annotated = results[0].plot()
            response_data["data"]["annotated_image"] = encode_image_to_base64(annotated)
        
        return JSONResponse(content=response_data)
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[Detect] é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=f"æ£€æµ‹å¤±è´¥: {str(e)}")


# ==================== å›¾åƒåˆ†ç±» API ====================
@app.post("/api/classify")
async def classify_image(request: ClassifyRequest):
    """
    å›¾åƒåˆ†ç±» APIï¼ˆJSON è¯·æ±‚ï¼‰- å¢å¼ºç‰ˆï¼Œæ”¯æŒåœºæ™¯åˆ†æ
    
    - image_base64: Base64 ç¼–ç çš„å›¾åƒ
    - conf: ç½®ä¿¡åº¦é˜ˆå€¼
    - top_k: è¿”å›å‰ k ä¸ªåˆ†ç±»ç»“æœ
    - analyze_scene: æ˜¯å¦åˆ†æåœºæ™¯ç±»å‹ï¼ˆé»˜è®¤å¼€å¯ï¼‰
    """
    try:
        logger.info(f"[Classify] æ”¶åˆ° JSON è¯·æ±‚ï¼Œåœºæ™¯åˆ†æ: {request.analyze_scene}")
        
        # è¯»å–å›¾åƒ
        image = read_image_from_base64(request.image_base64)
        
        # æ‰§è¡Œåˆ†ç±»
        model = model_manager.get_model('classify')
        results = model(image, conf=request.conf)
        
        # è§£æåˆ†ç±»ç»“æœ
        classifications = []
        for result in results:
            probs = result.probs
            if probs is not None:
                top_indices = probs.top5[:request.top_k] if hasattr(probs, 'top5') else []
                top_confs = probs.top5conf[:request.top_k] if hasattr(probs, 'top5conf') else []
                
                for idx, conf_score in zip(top_indices, top_confs):
                    # æ·»åŠ ä¸­æ–‡ç¿»è¯‘
                    class_name_en = result.names[idx]
                    class_name_cn = translate_class_name(class_name_en)
                    
                    classifications.append({
                        "class_id": int(idx),
                        "class_name": class_name_en,
                        "class_name_cn": class_name_cn,
                        "confidence": float(conf_score)
                    })
        
        response_data = {
            "success": True,
            "task": "classification",
            "message": f"åˆ†ç±»å®Œæˆï¼ŒTop-{len(classifications)} ç»“æœ",
            "data": {
                "classifications": classifications
            }
        }
        
        # åœºæ™¯åˆ†æ
        if request.analyze_scene:
            # åˆ†æå›¾åƒç‰¹å¾
            image_features = scene_analyzer.analyze_image_features(image)
            
            # å°è¯•è·å–ç›®æ ‡æ£€æµ‹ç»“æœä»¥è¾…åŠ©åœºæ™¯åˆ¤æ–­
            detected_objects = []
            try:
                detect_model = model_manager.get_model('detect')
                detect_results = detect_model(image, conf=0.3)
                for det_result in detect_results:
                    if det_result.boxes is not None:
                        for box in det_result.boxes:
                            detected_objects.append({
                                "class_name": det_result.names[int(box.cls[0])],
                                "confidence": float(box.conf[0])
                            })
            except Exception as e:
                logger.warning(f"ç›®æ ‡æ£€æµ‹è¾…åŠ©åˆ†æå¤±è´¥: {e}")
            
            # è¿›è¡Œåœºæ™¯åˆ†æ
            scene_analysis = scene_analyzer.classify_scene(
                classifications, 
                image_features, 
                detected_objects
            )
            
            response_data["data"]["scene_analysis"] = scene_analysis
            response_data["data"]["detected_objects"] = detected_objects[:10]  # æœ€å¤šè¿”å›10ä¸ªæ£€æµ‹å¯¹è±¡
            response_data["message"] = f"åˆ†ç±»å®Œæˆï¼š{scene_analysis['primary_scene']['name']}"
        
        return JSONResponse(content=response_data)
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[Classify] é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ†ç±»å¤±è´¥: {str(e)}")


# ==================== å¸¸ç”¨ç±»åˆ«ä¸­æ–‡ç¿»è¯‘ ====================
CLASS_NAME_TRANSLATIONS = {
    # äººç‰©ç›¸å…³
    "person": "äººç‰©", "man": "ç”·äºº", "woman": "å¥³äºº", "child": "å„¿ç«¥", "baby": "å©´å„¿",
    # åŠ¨ç‰©
    "dog": "ç‹—", "cat": "çŒ«", "bird": "é¸Ÿ", "horse": "é©¬", "sheep": "ç¾Š", "cow": "ç‰›",
    "elephant": "å¤§è±¡", "bear": "ç†Š", "zebra": "æ–‘é©¬", "giraffe": "é•¿é¢ˆé¹¿", "tiger": "è€è™",
    "lion": "ç‹®å­", "fish": "é±¼", "rabbit": "å…”å­", "monkey": "çŒ´å­",
    # äº¤é€šå·¥å…·
    "car": "æ±½è½¦", "truck": "å¡è½¦", "bus": "å…¬äº¤è½¦", "motorcycle": "æ‘©æ‰˜è½¦", "bicycle": "è‡ªè¡Œè½¦",
    "airplane": "é£æœº", "boat": "èˆ¹", "train": "ç«è½¦", "ship": "è½®èˆ¹",
    # å»ºç­‘å’ŒåŸå¸‚
    "building": "å»ºç­‘", "house": "æˆ¿å±‹", "skyscraper": "æ‘©å¤©å¤§æ¥¼", "bridge": "æ¡¥",
    "tower": "å¡”", "church": "æ•™å ‚", "castle": "åŸå ¡", "palace": "å®«æ®¿",
    # è‡ªç„¶
    "mountain": "å±±", "lake": "æ¹–", "river": "æ²³æµ", "ocean": "æµ·æ´‹", "beach": "æµ·æ»©",
    "forest": "æ£®æ—", "tree": "æ ‘", "flower": "èŠ±", "grass": "è‰åœ°", "sky": "å¤©ç©º",
    # é£Ÿç‰©
    "food": "é£Ÿç‰©", "pizza": "æŠ«è¨", "burger": "æ±‰å ¡", "cake": "è›‹ç³•", "fruit": "æ°´æœ",
    "apple": "è‹¹æœ", "banana": "é¦™è•‰", "orange": "æ©™å­", "bread": "é¢åŒ…",
    # ç”µå­è®¾å¤‡
    "phone": "æ‰‹æœº", "computer": "ç”µè„‘", "laptop": "ç¬”è®°æœ¬", "television": "ç”µè§†", "camera": "ç›¸æœº",
    # å…¶ä»–
    "book": "ä¹¦", "chair": "æ¤…å­", "table": "æ¡Œå­", "bed": "åºŠ", "sofa": "æ²™å‘",
    "lamp": "ç¯", "clock": "æ—¶é’Ÿ", "ball": "çƒ", "toy": "ç©å…·",
}


def translate_class_name(english_name: str) -> str:
    """å°†è‹±æ–‡ç±»åç¿»è¯‘ä¸ºä¸­æ–‡"""
    name_lower = english_name.lower().replace("_", " ")
    
    # ç›´æ¥åŒ¹é…
    if name_lower in CLASS_NAME_TRANSLATIONS:
        return CLASS_NAME_TRANSLATIONS[name_lower]
    
    # éƒ¨åˆ†åŒ¹é…
    for en, cn in CLASS_NAME_TRANSLATIONS.items():
        if en in name_lower or name_lower in en:
            return cn
    
    return english_name  # æ— æ³•ç¿»è¯‘åˆ™è¿”å›åŸå


# ==================== å§¿æ€ä¼°è®¡ API ====================
@app.post("/api/pose")
async def estimate_pose(request: PoseRequest):
    """
    å§¿æ€ä¼°è®¡ APIï¼ˆJSON è¯·æ±‚ï¼‰
    
    - image_base64: Base64 ç¼–ç çš„å›¾åƒ
    - conf: ç½®ä¿¡åº¦é˜ˆå€¼
    - iou: IoU é˜ˆå€¼
    - return_image: æ˜¯å¦è¿”å›æ ‡æ³¨åçš„å›¾åƒ
    """
    try:
        logger.info(f"[Pose] æ”¶åˆ° JSON è¯·æ±‚")
        
        # è¯»å–å›¾åƒ
        image = read_image_from_base64(request.image_base64)
        
        # æ‰§è¡Œå§¿æ€ä¼°è®¡
        model = model_manager.get_model('pose')
        results = model(image, conf=request.conf, iou=request.iou)
        
        # å…³é”®ç‚¹åç§°
        keypoint_names = [
            'nose', 'left_eye', 'right_eye', 'left_ear', 'right_ear',
            'left_shoulder', 'right_shoulder', 'left_elbow', 'right_elbow',
            'left_wrist', 'right_wrist', 'left_hip', 'right_hip',
            'left_knee', 'right_knee', 'left_ankle', 'right_ankle'
        ]
        
        # è§£æç»“æœ
        poses = []
        for result in results:
            if result.keypoints is not None:
                keypoints_data = result.keypoints
                boxes = result.boxes
                
                for i in range(len(keypoints_data)):
                    kpts = keypoints_data[i].xy[0].cpu().numpy()
                    kpts_conf = keypoints_data[i].conf[0].cpu().numpy() if keypoints_data[i].conf is not None else None
                    
                    # è·å–è¾¹ç•Œæ¡†
                    bbox = None
                    if boxes is not None and i < len(boxes):
                        x1, y1, x2, y2 = boxes[i].xyxy[0].cpu().numpy()
                        bbox = {
                            "x1": float(x1),
                            "y1": float(y1),
                            "x2": float(x2),
                            "y2": float(y2)
                        }
                    
                    # æ„å»ºå…³é”®ç‚¹ä¿¡æ¯
                    keypoints = []
                    for j, name in enumerate(keypoint_names):
                        if j < len(kpts):
                            keypoints.append({
                                "name": name,
                                "x": float(kpts[j][0]),
                                "y": float(kpts[j][1]),
                                "confidence": float(kpts_conf[j]) if kpts_conf is not None else 0.0
                            })
                    
                    poses.append({
                        "person_id": i,
                        "bbox": bbox,
                        "keypoints": keypoints
                    })
        
        response_data = {
            "success": True,
            "task": "pose_estimation",
            "message": f"æ£€æµ‹åˆ° {len(poses)} äºº",
            "data": {
                "poses": poses,
                "count": len(poses)
            }
        }
        
        # è¿”å›æ ‡æ³¨å›¾åƒ
        if request.return_image:
            annotated = results[0].plot()
            response_data["data"]["annotated_image"] = encode_image_to_base64(annotated)
        
        return JSONResponse(content=response_data)
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[Pose] é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å§¿æ€ä¼°è®¡å¤±è´¥: {str(e)}")


# ==================== å®ä¾‹åˆ†å‰² API ====================
@app.post("/api/segment")
async def segment_image(request: SegmentRequest):
    """
    å®ä¾‹åˆ†å‰² APIï¼ˆJSON è¯·æ±‚ï¼‰
    
    - image_base64: Base64 ç¼–ç çš„å›¾åƒ
    - conf: ç½®ä¿¡åº¦é˜ˆå€¼
    - iou: IoU é˜ˆå€¼
    - return_image: æ˜¯å¦è¿”å›æ ‡æ³¨åçš„å›¾åƒ
    """
    try:
        logger.info(f"[Segment] æ”¶åˆ° JSON è¯·æ±‚")
        
        # è¯»å–å›¾åƒ
        image = read_image_from_base64(request.image_base64)
        
        # æ‰§è¡Œåˆ†å‰²
        model = model_manager.get_model('segment')
        results = model(image, conf=request.conf, iou=request.iou)
        
        # è§£æç»“æœ
        segments = []
        for result in results:
            boxes = result.boxes
            masks = result.masks
            
            if boxes is not None:
                for i, box in enumerate(boxes):
                    x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()
                    segment_data = {
                        "class_id": int(box.cls[0]),
                        "class_name": result.names[int(box.cls[0])],
                        "confidence": float(box.conf[0]),
                        "bbox": {
                            "x1": float(x1),
                            "y1": float(y1),
                            "x2": float(x2),
                            "y2": float(y2)
                        }
                    }
                    segments.append(segment_data)
        
        response_data = {
            "success": True,
            "task": "segmentation",
            "message": f"åˆ†å‰²åˆ° {len(segments)} ä¸ªç›®æ ‡",
            "data": {
                "segments": segments,
                "count": len(segments)
            }
        }
        
        # è¿”å›æ ‡æ³¨å›¾åƒ
        if request.return_image:
            annotated = results[0].plot()
            response_data["data"]["annotated_image"] = encode_image_to_base64(annotated)
        
        return JSONResponse(content=response_data)
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[Segment] é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=f"åˆ†å‰²å¤±è´¥: {str(e)}")


# ==================== è…¾è®¯äº‘å›¾åƒåˆ†æ API ====================
@app.post("/api/tencent/detect")
async def tencent_detect_objects(request: TencentCloudRequest):
    """
    è…¾è®¯äº‘ç›®æ ‡æ£€æµ‹ API
    ä½¿ç”¨è…¾è®¯äº‘å›¾åƒåˆ†ææœåŠ¡è¿›è¡Œé«˜ç²¾åº¦ç›®æ ‡æ£€æµ‹
    
    - image_base64: Base64 ç¼–ç çš„å›¾åƒ
    - api_type: APIç±»å‹ (detect: ç›®æ ‡æ£€æµ‹, label: å›¾åƒæ ‡ç­¾, car: è½¦è¾†è¯†åˆ«)
    """
    try:
        logger.info(f"[TencentCloud] æ”¶åˆ°è¯·æ±‚ï¼ŒAPIç±»å‹: {request.api_type}")
        
        client = TencentCloudConfig.get_client()
        
        # å¤„ç† Base64 æ•°æ®ï¼ˆç§»é™¤å¯èƒ½çš„å‰ç¼€ï¼‰
        image_base64 = request.image_base64
        if ',' in image_base64:
            image_base64 = image_base64.split(',')[1]
        
        if request.api_type == "detect":
            # ç›®æ ‡æ£€æµ‹
            req = tiia_models.DetectLabelRequest()
            req.ImageBase64 = image_base64
            req.Scenes = ["CAMERA"]  # ç›¸æœºåœºæ™¯ï¼Œé€‚åˆé€šç”¨ç‰©ä½“æ£€æµ‹
            
            resp = client.DetectLabel(req)
            result = json.loads(resp.to_json_string())
            
            # è§£ææ ‡ç­¾ç»“æœ
            labels = []
            if "Labels" in result:
                for label in result["Labels"]:
                    labels.append({
                        "name": label.get("Name", ""),
                        "name_en": label.get("FirstCategory", ""),
                        "confidence": label.get("Confidence", 0) / 100,
                        "category": label.get("SecondCategory", "")
                    })
            
            return JSONResponse(content={
                "success": True,
                "task": "tencent_detect",
                "message": f"è…¾è®¯äº‘æ£€æµ‹å®Œæˆï¼Œè¯†åˆ«åˆ° {len(labels)} ä¸ªæ ‡ç­¾",
                "data": {
                    "labels": labels,
                    "count": len(labels),
                    "source": "tencent_cloud"
                }
            })
            
        elif request.api_type == "label":
            # å›¾åƒæ ‡ç­¾ï¼ˆæ›´è¯¦ç»†çš„åˆ†ç±»ï¼‰
            req = tiia_models.DetectLabelProRequest()
            req.ImageBase64 = image_base64
            
            resp = client.DetectLabelPro(req)
            result = json.loads(resp.to_json_string())
            
            labels = []
            if "Labels" in result:
                for label in result["Labels"]:
                    labels.append({
                        "name": label.get("Name", ""),
                        "confidence": label.get("Confidence", 0) / 100,
                        "first_category": label.get("FirstCategory", ""),
                        "second_category": label.get("SecondCategory", "")
                    })
            
            return JSONResponse(content={
                "success": True,
                "task": "tencent_label",
                "message": f"è…¾è®¯äº‘æ ‡ç­¾è¯†åˆ«å®Œæˆï¼Œè¯†åˆ«åˆ° {len(labels)} ä¸ªæ ‡ç­¾",
                "data": {
                    "labels": labels,
                    "count": len(labels),
                    "source": "tencent_cloud"
                }
            })
            
        elif request.api_type == "car":
            # è½¦è¾†è¯†åˆ«
            req = tiia_models.RecognizeCarRequest()
            req.ImageBase64 = image_base64
            
            resp = client.RecognizeCar(req)
            result = json.loads(resp.to_json_string())
            
            # æ‰“å°è°ƒè¯•ä¿¡æ¯
            logger.info(f"[TencentCloud] è½¦è¾†è¯†åˆ«åŸå§‹ç»“æœ: {result}")
            
            cars = []
            # å®‰å…¨è·å–åˆ—è¡¨ï¼Œå¤„ç† None çš„æƒ…å†µ
            car_coords = result.get("CarCoords") or []
            car_tags = result.get("CarTags") or []
            
            for i, coord in enumerate(car_coords):
                # å®‰å…¨è·å– car_info
                car_info = car_tags[i] if i < len(car_tags) else {}
                if car_info is None:
                    car_info = {}
                    
                cars.append({
                    "brand": car_info.get("Brand", "æœªçŸ¥") if car_info else "æœªçŸ¥",
                    "model": car_info.get("Type", "æœªçŸ¥") if car_info else "æœªçŸ¥",
                    "color": car_info.get("Color", "æœªçŸ¥") if car_info else "æœªçŸ¥",
                    "year": car_info.get("Year", "æœªçŸ¥") if car_info else "æœªçŸ¥",
                    "confidence": (car_info.get("Confidence", 0) or 0) / 100,
                    "bbox": {
                        "x1": coord.get("X", 0) if coord else 0,
                        "y1": coord.get("Y", 0) if coord else 0,
                        "x2": (coord.get("X", 0) or 0) + (coord.get("Width", 0) or 0) if coord else 0,
                        "y2": (coord.get("Y", 0) or 0) + (coord.get("Height", 0) or 0) if coord else 0
                    }
                })
            
            return JSONResponse(content={
                "success": True,
                "task": "tencent_car",
                "message": f"è…¾è®¯äº‘è½¦è¾†è¯†åˆ«å®Œæˆï¼Œè¯†åˆ«åˆ° {len(cars)} è¾†è½¦",
                "data": {
                    "cars": cars,
                    "count": len(cars),
                    "source": "tencent_cloud"
                }
            })
        else:
            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„ API ç±»å‹: {request.api_type}")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[TencentCloud] é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è…¾è®¯äº‘ API è°ƒç”¨å¤±è´¥: {str(e)}")


@app.get("/api/tencent/status")
async def tencent_cloud_status():
    """
    æ£€æŸ¥è…¾è®¯äº‘ API é…ç½®çŠ¶æ€
    """
    return JSONResponse(content={
        "success": True,
        "data": {
            "sdk_installed": TENCENT_CLOUD_AVAILABLE,
            "configured": TencentCloudConfig.is_configured(),
            "region": TencentCloudConfig.REGION,
            "message": "è…¾è®¯äº‘ API å·²å°±ç»ª" if (TENCENT_CLOUD_AVAILABLE and TencentCloudConfig.is_configured()) else "è¯·é…ç½®è…¾è®¯äº‘å¯†é’¥"
        }
    })


# ==================== è½¦ç‰Œè¯†åˆ« API (HyperLPR3) ====================

# è½¦ç‰Œç±»å‹æ˜ å°„
PLATE_TYPE_MAP = {
    0: "æœªçŸ¥",
    1: "è“ç‰Œ",
    2: "é»„ç‰Œ",
    3: "ç»¿ç‰Œ",
    4: "ç™½ç‰Œ",
    5: "é»‘ç‰Œ",
    6: "ç»¿ç‰Œ(å°å‹æ–°èƒ½æº)",
    7: "é»„ç»¿ç‰Œ(å¤§å‹æ–°èƒ½æº)",
}

PLATE_COLOR_MAP = {
    0: "æœªçŸ¥",
    1: "è“è‰²",
    2: "é»„è‰²", 
    3: "ç»¿è‰²",
    4: "ç™½è‰²",
    5: "é»‘è‰²",
    6: "æ¸å˜ç»¿",
    7: "é»„ç»¿æ¸å˜",
}


@app.post("/api/lpr")
async def recognize_license_plate(request: LPRRequest):
    """
    è½¦ç‰Œè¯†åˆ« API (ä½¿ç”¨ HyperLPR3)
    æ”¯æŒä¸­å›½å„ç±»è½¦ç‰Œï¼šè“ç‰Œã€é»„ç‰Œã€ç»¿ç‰Œï¼ˆæ–°èƒ½æºï¼‰ã€ç™½ç‰Œï¼ˆå†›è­¦ï¼‰ã€é»‘ç‰Œï¼ˆå¤–ä¼ï¼‰
    
    - image_base64: Base64 ç¼–ç çš„å›¾åƒ
    - return_image: æ˜¯å¦è¿”å›æ ‡æ³¨åçš„å›¾åƒ
    """
    try:
        if not HYPERLPR_AVAILABLE or lpr_model is None:
            raise HTTPException(
                status_code=500, 
                detail="HyperLPR3 æœªå®‰è£…æˆ–åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·å®‰è£…ï¼špip install hyperlpr3"
            )
        
        logger.info(f"[LPR] æ”¶åˆ°è½¦ç‰Œè¯†åˆ«è¯·æ±‚")
        
        # è¯»å–å›¾åƒ
        image = read_image_from_base64(request.image_base64)
        
        # è½¬æ¢ä¸ºRGBï¼ˆHyperLPR3 éœ€è¦ RGB æ ¼å¼ï¼‰
        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # æ‰§è¡Œè½¦ç‰Œè¯†åˆ«
        results = lpr_model(image_rgb)
        
        # è§£æç»“æœ
        plates = []
        for result in results:
            # HyperLPR3 è¿”å›æ ¼å¼: (è½¦ç‰Œå·, ç½®ä¿¡åº¦, è½¦ç‰Œç±»å‹ID, è¾¹ç•Œæ¡†)
            plate_number = result[0]  # è½¦ç‰Œå·ç 
            confidence = float(result[1])  # ç½®ä¿¡åº¦
            plate_type_id = int(result[2]) if len(result) > 2 else 0  # è½¦ç‰Œç±»å‹
            bbox = result[3] if len(result) > 3 else [0, 0, 0, 0]  # è¾¹ç•Œæ¡† [x1, y1, x2, y2]
            
            plates.append({
                "plate_number": plate_number,
                "plate_type": PLATE_TYPE_MAP.get(plate_type_id, "æœªçŸ¥"),
                "plate_color": PLATE_COLOR_MAP.get(plate_type_id, "æœªçŸ¥"),
                "confidence": confidence,
                "bbox": {
                    "x1": float(bbox[0]),
                    "y1": float(bbox[1]),
                    "x2": float(bbox[2]),
                    "y2": float(bbox[3])
                }
            })
        
        response_data = {
            "success": True,
            "task": "license_plate_recognition",
            "message": f"è¯†åˆ«åˆ° {len(plates)} ä¸ªè½¦ç‰Œ",
            "data": {
                "plates": plates,
                "count": len(plates)
            }
        }
        
        # è¿”å›æ ‡æ³¨å›¾åƒ
        if request.return_image and len(plates) > 0:
            annotated = image.copy()
            for plate in plates:
                bbox = plate["bbox"]
                x1, y1 = int(bbox["x1"]), int(bbox["y1"])
                x2, y2 = int(bbox["x2"]), int(bbox["y2"])
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                cv2.rectangle(annotated, (x1, y1), (x2, y2), (0, 255, 0), 2)
                
                # ç»˜åˆ¶è½¦ç‰Œå·æ–‡æœ¬èƒŒæ™¯
                text = plate["plate_number"]
                font = cv2.FONT_HERSHEY_SIMPLEX
                font_scale = 0.8
                thickness = 2
                (text_w, text_h), baseline = cv2.getTextSize(text, font, font_scale, thickness)
                
                # æ–‡æœ¬èƒŒæ™¯æ¡†
                cv2.rectangle(annotated, (x1, y1 - text_h - 10), (x1 + text_w + 10, y1), (0, 255, 0), -1)
                
                # ç”±äº OpenCV ä¸æ”¯æŒä¸­æ–‡ï¼Œä½¿ç”¨ PIL ç»˜åˆ¶ä¸­æ–‡
                try:
                    from PIL import Image, ImageDraw, ImageFont
                    pil_img = Image.fromarray(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))
                    draw = ImageDraw.Draw(pil_img)
                    
                    # å°è¯•åŠ è½½ä¸­æ–‡å­—ä½“
                    try:
                        font_path = "/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc"
                        pil_font = ImageFont.truetype(font_path, 24)
                    except:
                        try:
                            font_path = "C:/Windows/Fonts/msyh.ttc"
                            pil_font = ImageFont.truetype(font_path, 24)
                        except:
                            pil_font = ImageFont.load_default()
                    
                    draw.text((x1 + 5, y1 - text_h - 8), text, font=pil_font, fill=(0, 0, 0))
                    annotated = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
                except Exception as e:
                    logger.warning(f"ç»˜åˆ¶ä¸­æ–‡å¤±è´¥: {e}")
                    # é™çº§ä½¿ç”¨è‹±æ–‡æ˜¾ç¤º
                    cv2.putText(annotated, text, (x1 + 5, y1 - 5), font, font_scale, (0, 0, 0), thickness)
            
            response_data["data"]["annotated_image"] = encode_image_to_base64(annotated)
        
        return JSONResponse(content=response_data)
    
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[LPR] é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è½¦ç‰Œè¯†åˆ«å¤±è´¥: {str(e)}")


@app.get("/api/lpr/status")
async def lpr_status():
    """
    æ£€æŸ¥è½¦ç‰Œè¯†åˆ« API çŠ¶æ€
    """
    return JSONResponse(content={
        "success": True,
        "data": {
            "available": HYPERLPR_AVAILABLE,
            "model_loaded": lpr_model is not None,
            "supported_types": list(PLATE_TYPE_MAP.values()),
            "message": "è½¦ç‰Œè¯†åˆ« API å·²å°±ç»ª" if HYPERLPR_AVAILABLE else "HyperLPR3 æœªå®‰è£…"
        }
    })


# ==================== ç™¾åº¦ AI å¼€æ”¾å¹³å° API ====================
@app.post("/api/baidu/detect")
async def baidu_ai_detect(request: BaiduAIRequest):
    """
    ç™¾åº¦ AI å›¾åƒè¯†åˆ« API
    æ”¯æŒå›¾åƒåˆ†ç±»ã€ç‰©ä½“æ£€æµ‹ã€äººè„¸è¯†åˆ«
    
    - image_base64: Base64 ç¼–ç çš„å›¾åƒ
    - api_type: APIç±»å‹ (classify: å›¾åƒåˆ†ç±», detect: ç‰©ä½“æ£€æµ‹, face: äººè„¸è¯†åˆ«)
    """
    try:
        logger.info(f"[BaiduAI] æ”¶åˆ°è¯·æ±‚ï¼ŒAPIç±»å‹: {request.api_type}")
        
        # å¤„ç† Base64 æ•°æ®ï¼ˆç§»é™¤å¯èƒ½çš„å‰ç¼€ï¼‰
        image_base64 = request.image_base64
        if ',' in image_base64:
            image_base64 = image_base64.split(',')[1]
        
        # å°† Base64 è½¬æ¢ä¸ºäºŒè¿›åˆ¶
        image_bytes = base64.b64decode(image_base64)
        
        if request.api_type == "classify":
            # å›¾åƒåˆ†ç±» - ä½¿ç”¨é€šç”¨ç‰©ä½“å’Œåœºæ™¯è¯†åˆ«
            client = BaiduAIConfig.get_image_client()
            
            # è°ƒç”¨é€šç”¨ç‰©ä½“å’Œåœºæ™¯è¯†åˆ«æ¥å£
            result = client.advancedGeneral(image_bytes)
            
            logger.info(f"[BaiduAI] å›¾åƒåˆ†ç±»åŸå§‹ç»“æœ: {result}")
            
            # æ£€æŸ¥é”™è¯¯
            if "error_code" in result:
                raise HTTPException(
                    status_code=500, 
                    detail=f"ç™¾åº¦ AI é”™è¯¯: {result.get('error_msg', 'æœªçŸ¥é”™è¯¯')} (é”™è¯¯ç : {result.get('error_code')})"
                )
            
            # è§£æç»“æœ
            items = []
            result_list = result.get("result") or []
            for item in result_list:
                items.append({
                    "name": item.get("keyword", ""),
                    "confidence": item.get("score", 0),
                    "root": item.get("root", ""),
                    "baike_url": item.get("baike_info", {}).get("baike_url", ""),
                    "description": item.get("baike_info", {}).get("description", "")
                })
            
            return JSONResponse(content={
                "success": True,
                "task": "baidu_classify",
                "message": f"ç™¾åº¦ AI å›¾åƒåˆ†ç±»å®Œæˆï¼Œè¯†åˆ«åˆ° {len(items)} ä¸ªç»“æœ",
                "data": {
                    "items": items,
                    "count": len(items),
                    "log_id": result.get("log_id"),
                    "source": "baidu_ai"
                }
            })
            
        elif request.api_type == "detect":
            # ç‰©ä½“æ£€æµ‹ - ä½¿ç”¨å›¾åƒä¸»ä½“æ£€æµ‹
            client = BaiduAIConfig.get_image_client()
            
            # è°ƒç”¨ç‰©ä½“æ£€æµ‹æ¥å£
            result = client.objectDetect(image_bytes)
            
            logger.info(f"[BaiduAI] ç‰©ä½“æ£€æµ‹åŸå§‹ç»“æœ: {result}")
            
            # æ£€æŸ¥é”™è¯¯
            if "error_code" in result:
                raise HTTPException(
                    status_code=500, 
                    detail=f"ç™¾åº¦ AI é”™è¯¯: {result.get('error_msg', 'æœªçŸ¥é”™è¯¯')} (é”™è¯¯ç : {result.get('error_code')})"
                )
            
            # è§£æç»“æœ
            objects = []
            result_obj = result.get("result") or {}
            
            # ä¸»ä½“æ£€æµ‹è¿”å›æ ¼å¼ä¸åŒï¼Œéœ€è¦å¤„ç†
            if "left" in result_obj:
                # å•ä¸ªä¸»ä½“æ£€æµ‹ç»“æœ
                objects.append({
                    "name": "ä¸»ä½“",
                    "confidence": 1.0,
                    "bbox": {
                        "x1": result_obj.get("left", 0),
                        "y1": result_obj.get("top", 0),
                        "x2": result_obj.get("left", 0) + result_obj.get("width", 0),
                        "y2": result_obj.get("top", 0) + result_obj.get("height", 0)
                    }
                })
            
            return JSONResponse(content={
                "success": True,
                "task": "baidu_detect",
                "message": f"ç™¾åº¦ AI ç‰©ä½“æ£€æµ‹å®Œæˆï¼Œæ£€æµ‹åˆ° {len(objects)} ä¸ªç›®æ ‡",
                "data": {
                    "objects": objects,
                    "count": len(objects),
                    "log_id": result.get("log_id"),
                    "source": "baidu_ai"
                }
            })
            
        elif request.api_type == "face":
            # äººè„¸è¯†åˆ«
            face_client = BaiduAIConfig.get_face_client()
            
            # è°ƒç”¨äººè„¸æ£€æµ‹æ¥å£
            result = face_client.detect(image_base64, "BASE64", {
                "face_field": "age,beauty,expression,face_shape,gender,glasses,landmark,landmark150,quality,eye_status,emotion,face_type,mask,spoofing",
                "max_face_num": 10,
                "face_type": "LIVE",
                "liveness_control": "NONE"
            })
            
            logger.info(f"[BaiduAI] äººè„¸è¯†åˆ«åŸå§‹ç»“æœ: {result}")
            
            # æ£€æŸ¥é”™è¯¯
            if result.get("error_code", 0) != 0:
                error_msg = result.get("error_msg", "æœªçŸ¥é”™è¯¯")
                # ç‰¹æ®Šå¤„ç†ï¼šæ²¡æœ‰æ£€æµ‹åˆ°äººè„¸ä¸ç®—é”™è¯¯
                if result.get("error_code") == 222202:
                    return JSONResponse(content={
                        "success": True,
                        "task": "baidu_face",
                        "message": "æœªæ£€æµ‹åˆ°äººè„¸",
                        "data": {
                            "faces": [],
                            "count": 0,
                            "source": "baidu_ai"
                        }
                    })
                raise HTTPException(
                    status_code=500, 
                    detail=f"ç™¾åº¦ AI é”™è¯¯: {error_msg} (é”™è¯¯ç : {result.get('error_code')})"
                )
            
            # è§£æäººè„¸ç»“æœ
            faces = []
            face_result = result.get("result") or {}
            face_list = face_result.get("face_list") or []
            
            for i, face in enumerate(face_list):
                location = face.get("location", {})
                
                # è¡¨æƒ…æ˜ å°„
                expression_map = {
                    "none": "æ— è¡¨æƒ…",
                    "smile": "å¾®ç¬‘",
                    "laugh": "å¤§ç¬‘"
                }
                expression_type = face.get("expression", {}).get("type", "none")
                
                # æƒ…ç»ªæ˜ å°„
                emotion_map = {
                    "angry": "æ„¤æ€’",
                    "disgust": "åŒæ¶",
                    "fear": "ææƒ§",
                    "happy": "é«˜å…´",
                    "sad": "æ‚²ä¼¤",
                    "surprise": "æƒŠè®¶",
                    "neutral": "å¹³é™"
                }
                emotion_type = face.get("emotion", {}).get("type", "neutral")
                
                # æ€§åˆ«æ˜ å°„
                gender_map = {
                    "male": "ç”·æ€§",
                    "female": "å¥³æ€§"
                }
                gender_type = face.get("gender", {}).get("type", "")
                
                faces.append({
                    "face_id": i + 1,
                    "age": face.get("age", 0),
                    "beauty": face.get("beauty", 0),
                    "gender": gender_map.get(gender_type, "æœªçŸ¥"),
                    "gender_confidence": face.get("gender", {}).get("probability", 0),
                    "expression": expression_map.get(expression_type, "æœªçŸ¥"),
                    "expression_confidence": face.get("expression", {}).get("probability", 0),
                    "emotion": emotion_map.get(emotion_type, "æœªçŸ¥"),
                    "emotion_confidence": face.get("emotion", {}).get("probability", 0),
                    "glasses": "æˆ´çœ¼é•œ" if face.get("glasses", {}).get("type", "none") != "none" else "æ— çœ¼é•œ",
                    "mask": "æˆ´å£ç½©" if face.get("mask", {}).get("type", 0) == 1 else "æ— å£ç½©",
                    "face_shape": face.get("face_shape", {}).get("type", "æœªçŸ¥"),
                    "face_probability": face.get("face_probability", 0),
                    "bbox": {
                        "x1": location.get("left", 0),
                        "y1": location.get("top", 0),
                        "x2": location.get("left", 0) + location.get("width", 0),
                        "y2": location.get("top", 0) + location.get("height", 0)
                    },
                    "rotation_angle": location.get("rotation", 0)
                })
            
            return JSONResponse(content={
                "success": True,
                "task": "baidu_face",
                "message": f"ç™¾åº¦ AI äººè„¸è¯†åˆ«å®Œæˆï¼Œæ£€æµ‹åˆ° {len(faces)} å¼ äººè„¸",
                "data": {
                    "faces": faces,
                    "count": len(faces),
                    "log_id": result.get("log_id"),
                    "source": "baidu_ai"
                }
            })
            
        else:
            raise HTTPException(status_code=400, detail=f"ä¸æ”¯æŒçš„ API ç±»å‹: {request.api_type}")
            
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"[BaiduAI] é”™è¯¯: {str(e)}")
        raise HTTPException(status_code=500, detail=f"ç™¾åº¦ AI API è°ƒç”¨å¤±è´¥: {str(e)}")


@app.get("/api/baidu/status")
async def baidu_ai_status():
    """
    æ£€æŸ¥ç™¾åº¦ AI API é…ç½®çŠ¶æ€
    """
    return JSONResponse(content={
        "success": True,
        "data": {
            "sdk_installed": BAIDU_AI_AVAILABLE,
            "configured": BaiduAIConfig.is_configured(),
            "message": "ç™¾åº¦ AI API å·²å°±ç»ª" if (BAIDU_AI_AVAILABLE and BaiduAIConfig.is_configured()) else "è¯·é…ç½®ç™¾åº¦ AI å¯†é’¥"
        }
    })


# ==================== å¯åŠ¨æœåŠ¡ ====================
if __name__ == "__main__":
    import uvicorn
    
    print("=" * 60)
    print("YOLO11 è§†è§‰è¯†åˆ« API æœåŠ¡")
    print("=" * 60)
    print("API æ–‡æ¡£: http://localhost:8000/docs")
    print("æ”¯æŒ JSON è¯·æ±‚ï¼Œæ— å¤§å°é™åˆ¶")
    print("=" * 60)
    print(f"è…¾è®¯äº‘ SDK: {'å·²å®‰è£…' if TENCENT_CLOUD_AVAILABLE else 'æœªå®‰è£…'}")
    print(f"è…¾è®¯äº‘é…ç½®: {'å·²é…ç½®' if TencentCloudConfig.is_configured() else 'æœªé…ç½®'}")
    print(f"ç™¾åº¦ AI SDK: {'å·²å®‰è£…' if BAIDU_AI_AVAILABLE else 'æœªå®‰è£…'}")
    print(f"ç™¾åº¦ AI é…ç½®: {'å·²é…ç½®' if BaiduAIConfig.is_configured() else 'æœªé…ç½®'}")
    print(f"HyperLPR3 è½¦ç‰Œè¯†åˆ«: {'å·²åŠ è½½' if HYPERLPR_AVAILABLE else 'æœªå®‰è£…'}")
    print("=" * 60)
    
    uvicorn.run(app, host="0.0.0.0", port=8000)
