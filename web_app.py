"""
YOLO11 å¯è§†åŒ– Web åº”ç”¨
ä½¿ç”¨ Streamlit æ„å»ºäº¤äº’å¼ç•Œé¢
è¿è¡Œå‘½ä»¤: streamlit run web_app.py
"""

import streamlit as st
import cv2
import numpy as np
from PIL import Image
from ultralytics import YOLO
import tempfile
import os
from pathlib import Path


# é¡µé¢é…ç½®
st.set_page_config(
    page_title="YOLO11 è§†è§‰è¯†åˆ«ç³»ç»Ÿ",
    page_icon="ğŸ¯",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰æ ·å¼
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        text-align: center;
        color: #1E88E5;
        margin-bottom: 2rem;
    }
    .task-card {
        padding: 1rem;
        border-radius: 10px;
        background-color: #f0f2f6;
        margin: 0.5rem 0;
    }
    .result-box {
        padding: 1rem;
        border-radius: 5px;
        background-color: #e8f5e9;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)


@st.cache_resource
def load_model(task: str) -> YOLO:
    """åŠ è½½å¹¶ç¼“å­˜æ¨¡å‹"""
    model_paths = {
        'detect': 'yolo11n.pt',
        'classify': 'yolo11n-cls.pt',
        'pose': 'yolo11n-pose.pt',
        'segment': 'yolo11n-seg.pt',
    }
    return YOLO(model_paths[task])


def process_image(image: np.ndarray, task: str, conf: float) -> tuple:
    """å¤„ç†å›¾åƒå¹¶è¿”å›ç»“æœ"""
    model = load_model(task)
    results = model(image, conf=conf)
    
    # è·å–æ ‡æ³¨åçš„å›¾åƒ
    annotated_image = results[0].plot()
    
    # æå–ç»“æœä¿¡æ¯
    result_info = []
    
    if task == 'detect':
        boxes = results[0].boxes
        if boxes is not None:
            for box in boxes:
                class_name = results[0].names[int(box.cls[0])]
                confidence = float(box.conf[0])
                result_info.append(f"ğŸ¯ {class_name}: {confidence:.2%}")
    
    elif task == 'classify':
        probs = results[0].probs
        if probs is not None:
            top5_indices = probs.top5
            top5_confs = probs.top5conf
            for idx, conf_score in zip(top5_indices, top5_confs):
                class_name = results[0].names[idx]
                result_info.append(f"ğŸ“Š {class_name}: {float(conf_score):.2%}")
    
    elif task == 'pose':
        keypoints = results[0].keypoints
        if keypoints is not None:
            num_people = len(keypoints)
            result_info.append(f"ğŸ‘¤ æ£€æµ‹åˆ° {num_people} äºº")
            for i in range(num_people):
                kpts = keypoints[i].xy[0].cpu().numpy()
                visible = sum(1 for kpt in kpts if kpt[0] > 0 and kpt[1] > 0)
                result_info.append(f"  äººç‰© {i+1}: {visible} ä¸ªå¯è§å…³é”®ç‚¹")
    
    elif task == 'segment':
        masks = results[0].masks
        boxes = results[0].boxes
        if masks is not None and boxes is not None:
            for i, box in enumerate(boxes):
                class_name = results[0].names[int(box.cls[0])]
                confidence = float(box.conf[0])
                result_info.append(f"ğŸ­ {class_name}: {confidence:.2%}")
    
    return annotated_image, result_info


def main():
    """ä¸»å‡½æ•°"""
    # æ ‡é¢˜
    st.markdown('<p class="main-header">ğŸ¯ YOLO11 å¤šåŠŸèƒ½è§†è§‰è¯†åˆ«ç³»ç»Ÿ</p>', unsafe_allow_html=True)
    
    # ä¾§è¾¹æ 
    with st.sidebar:
        st.header("âš™ï¸ è®¾ç½®")
        
        # ä»»åŠ¡é€‰æ‹©
        task = st.selectbox(
            "é€‰æ‹©ä»»åŠ¡ç±»å‹",
            options=['detect', 'classify', 'pose', 'segment'],
            format_func=lambda x: {
                'detect': 'ğŸ¯ ç›®æ ‡æ£€æµ‹',
                'classify': 'ğŸ“Š å›¾åƒåˆ†ç±»',
                'pose': 'ğŸƒ å§¿æ€ä¼°è®¡',
                'segment': 'ğŸ­ å®ä¾‹åˆ†å‰²'
            }[x]
        )
        
        # ç½®ä¿¡åº¦é˜ˆå€¼
        conf_threshold = st.slider(
            "ç½®ä¿¡åº¦é˜ˆå€¼",
            min_value=0.0,
            max_value=1.0,
            value=0.25,
            step=0.05
        )
        
        # è¾“å…¥æºé€‰æ‹©
        input_source = st.radio(
            "é€‰æ‹©è¾“å…¥æº",
            options=['upload', 'camera', 'url'],
            format_func=lambda x: {
                'upload': 'ğŸ“ ä¸Šä¼ æ–‡ä»¶',
                'camera': 'ğŸ“· æ‘„åƒå¤´',
                'url': 'ğŸ”— URL é“¾æ¥'
            }[x]
        )
        
        st.markdown("---")
        st.markdown("### ğŸ“– åŠŸèƒ½è¯´æ˜")
        st.markdown("""
        - **ç›®æ ‡æ£€æµ‹**: æ£€æµ‹å›¾åƒä¸­çš„ç‰©ä½“ä½ç½®å’Œç±»åˆ«
        - **å›¾åƒåˆ†ç±»**: å¯¹æ•´å¼ å›¾ç‰‡è¿›è¡Œåˆ†ç±»
        - **å§¿æ€ä¼°è®¡**: æ£€æµ‹äººä½“å…³é”®ç‚¹å’Œéª¨æ¶
        - **å®ä¾‹åˆ†å‰²**: åƒç´ çº§çš„ç‰©ä½“åˆ†å‰²
        """)
    
    # ä¸»å†…å®¹åŒº
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“¥ è¾“å…¥")
        
        image = None
        
        if input_source == 'upload':
            uploaded_file = st.file_uploader(
                "ä¸Šä¼ å›¾åƒæˆ–è§†é¢‘",
                type=['jpg', 'jpeg', 'png', 'bmp', 'gif', 'webp', 'mp4', 'avi', 'mov']
            )
            
            if uploaded_file is not None:
                file_type = uploaded_file.type
                
                if file_type.startswith('image'):
                    image = Image.open(uploaded_file)
                    image = np.array(image)
                    st.image(image, caption="ä¸Šä¼ çš„å›¾åƒ", use_container_width=True)
                
                elif file_type.startswith('video'):
                    # ä¿å­˜è§†é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
                    tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
                    tfile.write(uploaded_file.read())
                    tfile.close()
                    
                    st.video(tfile.name)
                    
                    if st.button("ğŸ¬ å¤„ç†è§†é¢‘"):
                        with st.spinner("æ­£åœ¨å¤„ç†è§†é¢‘..."):
                            model = load_model(task if task != 'classify' else 'detect')
                            
                            # åˆ›å»ºè¾“å‡ºç›®å½•
                            output_dir = Path("runs") / task
                            output_dir.mkdir(parents=True, exist_ok=True)
                            
                            results = model(
                                tfile.name,
                                conf=conf_threshold,
                                save=True
                            )
                            
                            st.success("âœ… è§†é¢‘å¤„ç†å®Œæˆï¼")
                            st.info(f"ç»“æœä¿å­˜åœ¨: {output_dir}")
                    
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    os.unlink(tfile.name)
        
        elif input_source == 'camera':
            camera_image = st.camera_input("ğŸ“· æ‹æ‘„ç…§ç‰‡")
            
            if camera_image is not None:
                image = Image.open(camera_image)
                image = np.array(image)
        
        elif input_source == 'url':
            url = st.text_input("è¾“å…¥å›¾åƒ URL")
            
            if url:
                try:
                    import urllib.request
                    with urllib.request.urlopen(url) as response:
                        arr = np.asarray(bytearray(response.read()), dtype=np.uint8)
                        image = cv2.imdecode(arr, cv2.IMREAD_COLOR)
                        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                        st.image(image, caption="URL å›¾åƒ", use_container_width=True)
                except Exception as e:
                    st.error(f"æ— æ³•åŠ è½½å›¾åƒ: {e}")
    
    with col2:
        st.subheader("ğŸ“¤ è¾“å‡º")
        
        if image is not None:
            if st.button("ğŸš€ å¼€å§‹å¤„ç†", type="primary", use_container_width=True):
                with st.spinner("æ­£åœ¨å¤„ç†..."):
                    try:
                        annotated_image, result_info = process_image(
                            image, task, conf_threshold
                        )
                        
                        # æ˜¾ç¤ºå¤„ç†åçš„å›¾åƒ
                        st.image(
                            annotated_image,
                            caption="å¤„ç†ç»“æœ",
                            use_container_width=True
                        )
                        
                        # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
                        st.markdown("### ğŸ“‹ æ£€æµ‹ç»“æœ")
                        if result_info:
                            for info in result_info:
                                st.markdown(f'<div class="result-box">{info}</div>', unsafe_allow_html=True)
                        else:
                            st.info("æœªæ£€æµ‹åˆ°ç›®æ ‡")
                        
                        # ä¸‹è½½æŒ‰é’®
                        result_image = Image.fromarray(annotated_image)
                        import io
                        buf = io.BytesIO()
                        result_image.save(buf, format='PNG')
                        
                        st.download_button(
                            label="ğŸ’¾ ä¸‹è½½ç»“æœå›¾åƒ",
                            data=buf.getvalue(),
                            file_name="yolo_result.png",
                            mime="image/png"
                        )
                        
                    except Exception as e:
                        st.error(f"å¤„ç†å‡ºé”™: {e}")
        else:
            st.info("ğŸ‘ˆ è¯·å…ˆé€‰æ‹©æˆ–ä¸Šä¼ å›¾åƒ")
    
    # åº•éƒ¨ä¿¡æ¯
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666;">
        <p>åŸºäº YOLO11 + Ultralytics + Streamlit æ„å»º</p>
        <p>æ”¯æŒå›¾åƒåˆ†ç±»ã€ç›®æ ‡æ£€æµ‹ã€ç›®æ ‡è·Ÿè¸ªã€å§¿æ€ä¼°è®¡</p>
    </div>
    """, unsafe_allow_html=True)


if __name__ == "__main__":
    main()
