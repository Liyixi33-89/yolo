"""
YOLO11 å·¥å…·å‡½æ•°
åŒ…å«å›¾åƒå¤„ç†ã€ç»“æœå¯è§†åŒ–ç­‰è¾…åŠ©åŠŸèƒ½
"""

import cv2
import numpy as np
from typing import List, Tuple, Optional, Dict
from pathlib import Path


# COCO æ•°æ®é›†ç±»åˆ«é¢œè‰²æ˜ å°„
COLORS = [
    (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0),
    (255, 0, 255), (0, 255, 255), (128, 0, 0), (0, 128, 0),
    (0, 0, 128), (128, 128, 0), (128, 0, 128), (0, 128, 128),
    (255, 128, 0), (255, 0, 128), (128, 255, 0), (0, 255, 128),
    (128, 0, 255), (0, 128, 255), (255, 128, 128), (128, 255, 128)
]


# å§¿æ€ä¼°è®¡éª¨æ¶è¿æ¥å®šä¹‰
SKELETON_CONNECTIONS = [
    (0, 1), (0, 2),     # é¼»å­ -> çœ¼ç›
    (1, 3), (2, 4),     # çœ¼ç› -> è€³æœµ
    (5, 6),             # è‚©è†€è¿æ¥
    (5, 7), (7, 9),     # å·¦è‡‚
    (6, 8), (8, 10),    # å³è‡‚
    (5, 11), (6, 12),   # è‚©è†€ -> è‡€éƒ¨
    (11, 12),           # è‡€éƒ¨è¿æ¥
    (11, 13), (13, 15), # å·¦è…¿
    (12, 14), (14, 16)  # å³è…¿
]


def load_image(source: str) -> np.ndarray:
    """
    åŠ è½½å›¾åƒ
    
    Args:
        source: å›¾åƒè·¯å¾„æˆ– URL
        
    Returns:
        BGR æ ¼å¼çš„å›¾åƒæ•°ç»„
    """
    if source.startswith(('http://', 'https://')):
        import urllib.request
        with urllib.request.urlopen(source) as response:
            arr = np.asarray(bytearray(response.read()), dtype=np.uint8)
            image = cv2.imdecode(arr, cv2.IMREAD_COLOR)
    else:
        image = cv2.imread(source)
    
    if image is None:
        raise ValueError(f"æ— æ³•åŠ è½½å›¾åƒ: {source}")
    
    return image


def resize_image(
    image: np.ndarray,
    max_size: int = 1280,
    keep_aspect: bool = True
) -> np.ndarray:
    """
    è°ƒæ•´å›¾åƒå¤§å°
    
    Args:
        image: è¾“å…¥å›¾åƒ
        max_size: æœ€å¤§å°ºå¯¸
        keep_aspect: æ˜¯å¦ä¿æŒå®½é«˜æ¯”
        
    Returns:
        è°ƒæ•´åçš„å›¾åƒ
    """
    h, w = image.shape[:2]
    
    if keep_aspect:
        scale = min(max_size / w, max_size / h)
        if scale < 1:
            new_w = int(w * scale)
            new_h = int(h * scale)
            image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)
    else:
        if w > max_size or h > max_size:
            image = cv2.resize(image, (max_size, max_size), interpolation=cv2.INTER_AREA)
    
    return image


def draw_bbox(
    image: np.ndarray,
    bbox: Tuple[float, float, float, float],
    label: str,
    color: Tuple[int, int, int] = (0, 255, 0),
    thickness: int = 2
) -> np.ndarray:
    """
    åœ¨å›¾åƒä¸Šç»˜åˆ¶è¾¹ç•Œæ¡†
    
    Args:
        image: è¾“å…¥å›¾åƒ
        bbox: è¾¹ç•Œæ¡†åæ ‡ (x1, y1, x2, y2)
        label: æ ‡ç­¾æ–‡æœ¬
        color: é¢œè‰²
        thickness: çº¿æ¡ç²—ç»†
        
    Returns:
        ç»˜åˆ¶åçš„å›¾åƒ
    """
    x1, y1, x2, y2 = map(int, bbox)
    
    # ç»˜åˆ¶è¾¹ç•Œæ¡†
    cv2.rectangle(image, (x1, y1), (x2, y2), color, thickness)
    
    # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
    (text_w, text_h), baseline = cv2.getTextSize(
        label, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1
    )
    cv2.rectangle(
        image,
        (x1, y1 - text_h - 10),
        (x1 + text_w + 10, y1),
        color,
        -1
    )
    
    # ç»˜åˆ¶æ ‡ç­¾æ–‡æœ¬
    cv2.putText(
        image,
        label,
        (x1 + 5, y1 - 5),
        cv2.FONT_HERSHEY_SIMPLEX,
        0.5,
        (255, 255, 255),
        1
    )
    
    return image


def draw_skeleton(
    image: np.ndarray,
    keypoints: np.ndarray,
    confidence_threshold: float = 0.5,
    color: Tuple[int, int, int] = (0, 255, 0)
) -> np.ndarray:
    """
    åœ¨å›¾åƒä¸Šç»˜åˆ¶éª¨æ¶
    
    Args:
        image: è¾“å…¥å›¾åƒ
        keypoints: å…³é”®ç‚¹æ•°ç»„ (17, 2) æˆ– (17, 3)
        confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        color: é¢œè‰²
        
    Returns:
        ç»˜åˆ¶åçš„å›¾åƒ
    """
    # ç»˜åˆ¶å…³é”®ç‚¹
    for i, kpt in enumerate(keypoints):
        x, y = int(kpt[0]), int(kpt[1])
        if x > 0 and y > 0:
            cv2.circle(image, (x, y), 5, color, -1)
    
    # ç»˜åˆ¶éª¨æ¶è¿æ¥
    for start, end in SKELETON_CONNECTIONS:
        if start < len(keypoints) and end < len(keypoints):
            x1, y1 = int(keypoints[start][0]), int(keypoints[start][1])
            x2, y2 = int(keypoints[end][0]), int(keypoints[end][1])
            
            if x1 > 0 and y1 > 0 and x2 > 0 and y2 > 0:
                cv2.line(image, (x1, y1), (x2, y2), color, 2)
    
    return image


def get_color_for_class(class_id: int) -> Tuple[int, int, int]:
    """
    è·å–ç±»åˆ«å¯¹åº”çš„é¢œè‰²
    
    Args:
        class_id: ç±»åˆ« ID
        
    Returns:
        BGR é¢œè‰²å…ƒç»„
    """
    return COLORS[class_id % len(COLORS)]


def calculate_iou(
    box1: Tuple[float, float, float, float],
    box2: Tuple[float, float, float, float]
) -> float:
    """
    è®¡ç®—ä¸¤ä¸ªè¾¹ç•Œæ¡†çš„ IoU
    
    Args:
        box1: ç¬¬ä¸€ä¸ªè¾¹ç•Œæ¡† (x1, y1, x2, y2)
        box2: ç¬¬äºŒä¸ªè¾¹ç•Œæ¡† (x1, y1, x2, y2)
        
    Returns:
        IoU å€¼
    """
    x1_1, y1_1, x2_1, y2_1 = box1
    x1_2, y1_2, x2_2, y2_2 = box2
    
    # è®¡ç®—äº¤é›†
    x1_i = max(x1_1, x1_2)
    y1_i = max(y1_1, y1_2)
    x2_i = min(x2_1, x2_2)
    y2_i = min(y2_1, y2_2)
    
    if x2_i < x1_i or y2_i < y1_i:
        return 0.0
    
    intersection = (x2_i - x1_i) * (y2_i - y1_i)
    
    # è®¡ç®—å¹¶é›†
    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)
    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)
    union = area1 + area2 - intersection
    
    return intersection / union if union > 0 else 0.0


def format_results_json(results: Dict) -> str:
    """
    å°†ç»“æœæ ¼å¼åŒ–ä¸º JSON å­—ç¬¦ä¸²
    
    Args:
        results: æ£€æµ‹ç»“æœå­—å…¸
        
    Returns:
        æ ¼å¼åŒ–çš„ JSON å­—ç¬¦ä¸²
    """
    import json
    return json.dumps(results, indent=2, ensure_ascii=False)


def save_results_to_file(
    results: Dict,
    output_path: str,
    format: str = 'json'
) -> None:
    """
    å°†ç»“æœä¿å­˜åˆ°æ–‡ä»¶
    
    Args:
        results: æ£€æµ‹ç»“æœå­—å…¸
        output_path: è¾“å‡ºè·¯å¾„
        format: è¾“å‡ºæ ¼å¼ ('json', 'txt')
    """
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    if format == 'json':
        import json
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(results, f, indent=2, ensure_ascii=False)
    
    elif format == 'txt':
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(f"ä»»åŠ¡: {results.get('task', 'unknown')}\n")
            f.write("-" * 50 + "\n")
            for item in results.get('results', []):
                f.write(str(item) + "\n")


def create_video_writer(
    output_path: str,
    fps: float,
    frame_size: Tuple[int, int],
    codec: str = 'mp4v'
) -> cv2.VideoWriter:
    """
    åˆ›å»ºè§†é¢‘å†™å…¥å™¨
    
    Args:
        output_path: è¾“å‡ºè·¯å¾„
        fps: å¸§ç‡
        frame_size: å¸§å¤§å° (width, height)
        codec: ç¼–ç å™¨
        
    Returns:
        VideoWriter å¯¹è±¡
    """
    fourcc = cv2.VideoWriter_fourcc(*codec)
    return cv2.VideoWriter(output_path, fourcc, fps, frame_size)


def process_video_frames(
    video_path: str,
    callback,
    max_frames: Optional[int] = None
) -> List:
    """
    å¤„ç†è§†é¢‘å¸§
    
    Args:
        video_path: è§†é¢‘è·¯å¾„
        callback: å¸§å¤„ç†å›è°ƒå‡½æ•°
        max_frames: æœ€å¤§å¤„ç†å¸§æ•°
        
    Returns:
        æ‰€æœ‰å¸§çš„å¤„ç†ç»“æœåˆ—è¡¨
    """
    cap = cv2.VideoCapture(video_path)
    results = []
    frame_count = 0
    
    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break
        
        result = callback(frame, frame_count)
        results.append(result)
        
        frame_count += 1
        if max_frames and frame_count >= max_frames:
            break
    
    cap.release()
    return results


def print_detection_summary(results: Dict) -> None:
    """
    æ‰“å°æ£€æµ‹ç»“æœæ‘˜è¦
    
    Args:
        results: æ£€æµ‹ç»“æœå­—å…¸
    """
    task = results.get('task', 'unknown')
    items = results.get('results', [])
    
    print(f"\n{'=' * 50}")
    print(f"ä»»åŠ¡ç±»å‹: {task}")
    print(f"æ£€æµ‹æ•°é‡: {len(items)}")
    print(f"{'=' * 50}")
    
    if task == 'classification':
        for item in items:
            print(f"  ğŸ“Š {item['class_name']}: {item['confidence']:.2%}")
    
    elif task == 'detection':
        class_counts = {}
        for item in items:
            class_name = item['class_name']
            class_counts[class_name] = class_counts.get(class_name, 0) + 1
        
        for class_name, count in class_counts.items():
            print(f"  ğŸ¯ {class_name}: {count} ä¸ª")
    
    elif task == 'pose_estimation':
        for item in items:
            visible_kpts = sum(1 for k in item['keypoints'] if k['confidence'] > 0.5)
            print(f"  ğŸ‘¤ äººç‰© {item['person_id']}: {visible_kpts} ä¸ªå¯è§å…³é”®ç‚¹")
    
    elif task == 'tracking':
        track_ids = set(item['track_id'] for item in items)
        print(f"  ğŸ”„ è·Ÿè¸ªç›®æ ‡æ•°: {len(track_ids)}")
    
    print(f"{'=' * 50}\n")
