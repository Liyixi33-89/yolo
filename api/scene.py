"""
åœºæ™¯åˆ†æå™¨æ¨¡å—
å°†ä½çº§åˆ†ç±»æ˜ å°„åˆ°é«˜çº§åœºæ™¯ç±»åˆ«
"""
import cv2
import numpy as np


class SceneAnalyzer:
    """åœºæ™¯åˆ†æå™¨ï¼šå°†ä½çº§åˆ†ç±»æ˜ å°„åˆ°é«˜çº§åœºæ™¯ç±»åˆ«"""
    
    # åœºæ™¯ç±»å‹å®šä¹‰
    SCENE_TYPES = {
        "portrait": {
            "name": "äººç‰©ç…§ç‰‡",
            "icon": "ğŸ‘¤",
            "description": "åŒ…å«äººç‰©çš„ç…§ç‰‡",
            "keywords": ["person", "face", "portrait", "people", "human", "man", "woman", "child", "baby"]
        },
        "animal": {
            "name": "åŠ¨ç‰©",
            "icon": "ğŸ¾",
            "description": "åŠ¨ç‰©ç…§ç‰‡",
            "keywords": ["dog", "cat", "bird", "fish", "horse", "elephant", "bear", "zebra", "giraffe", "cow", "sheep", "tiger", "lion", "monkey", "rabbit", "hamster", "pet"]
        },
        "cityscape": {
            "name": "åŸå¸‚é£æ™¯",
            "icon": "ğŸ™ï¸",
            "description": "åŸå¸‚å»ºç­‘å’Œè¡—æ™¯",
            "keywords": ["skyscraper", "building", "tower", "bridge", "street", "road", "traffic", "car", "bus", "train", "architecture", "city", "urban", "downtown", "office"]
        },
        "nature": {
            "name": "è‡ªç„¶é£æ™¯",
            "icon": "ğŸï¸",
            "description": "è‡ªç„¶é£å…‰å’Œæˆ·å¤–åœºæ™¯",
            "keywords": ["mountain", "lake", "river", "ocean", "sea", "beach", "forest", "tree", "flower", "garden", "sky", "cloud", "sunset", "sunrise", "landscape", "grass", "field", "valley"]
        },
        "food": {
            "name": "ç¾é£Ÿ",
            "icon": "ğŸ½ï¸",
            "description": "é£Ÿç‰©å’Œé¥®å“",
            "keywords": ["food", "pizza", "burger", "cake", "fruit", "vegetable", "bread", "coffee", "drink", "meal", "dinner", "breakfast", "lunch", "restaurant", "dish", "cuisine"]
        },
        "vehicle": {
            "name": "äº¤é€šå·¥å…·",
            "icon": "ğŸš—",
            "description": "è½¦è¾†å’Œäº¤é€šå·¥å…·",
            "keywords": ["car", "truck", "bus", "motorcycle", "bicycle", "airplane", "boat", "ship", "train", "vehicle", "automobile", "van"]
        },
        "indoor": {
            "name": "å®¤å†…åœºæ™¯",
            "icon": "ğŸ ",
            "description": "å®¤å†…ç¯å¢ƒå’Œå®¶å±…",
            "keywords": ["room", "furniture", "sofa", "chair", "table", "bed", "lamp", "desk", "kitchen", "bathroom", "bedroom", "living", "office", "interior"]
        },
        "sports": {
            "name": "è¿åŠ¨",
            "icon": "âš½",
            "description": "ä½“è‚²è¿åŠ¨ç›¸å…³",
            "keywords": ["ball", "football", "basketball", "tennis", "golf", "baseball", "soccer", "swimming", "running", "sport", "gym", "stadium", "athlete"]
        },
        "electronics": {
            "name": "ç”µå­è®¾å¤‡",
            "icon": "ğŸ“±",
            "description": "ç”µå­äº§å“å’Œè®¾å¤‡",
            "keywords": ["phone", "computer", "laptop", "keyboard", "mouse", "screen", "monitor", "television", "camera", "electronic", "device", "gadget"]
        },
        "art": {
            "name": "è‰ºæœ¯/åŠ¨æ¼«",
            "icon": "ğŸ¨",
            "description": "è‰ºæœ¯ä½œå“ã€æ’ç”»æˆ–åŠ¨æ¼«é£æ ¼",
            "keywords": ["painting", "art", "drawing", "illustration", "cartoon", "comic", "animation", "poster", "design", "graphic"]
        },
        "text": {
            "name": "æ–‡æœ¬/æ–‡æ¡£",
            "icon": "ğŸ“„",
            "description": "åŒ…å«æ–‡å­—çš„å›¾ç‰‡",
            "keywords": ["document", "paper", "book", "newspaper", "magazine", "text", "letter", "sign", "poster", "menu", "envelope", "notebook"]
        },
        "unknown": {
            "name": "å…¶ä»–",
            "icon": "â“",
            "description": "æ— æ³•ç¡®å®šçš„åœºæ™¯ç±»å‹",
            "keywords": []
        }
    }
    
    # å›¾åƒç‰¹å¾åˆ†æé˜ˆå€¼
    COLOR_THRESHOLDS = {
        "anime_saturation": 0.6,  # åŠ¨æ¼«é€šå¸¸è‰²å½©é¥±å’Œåº¦é«˜
        "anime_edge_ratio": 0.15,  # åŠ¨æ¼«è¾¹ç¼˜æ¸…æ™°
    }
    
    @classmethod
    def analyze_image_features(cls, image: np.ndarray) -> dict:
        """åˆ†æå›¾åƒç‰¹å¾"""
        features = {}
        
        # è½¬æ¢åˆ°HSVé¢œè‰²ç©ºé—´
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        
        # è®¡ç®—é¥±å’Œåº¦å‡å€¼ï¼ˆåŠ¨æ¼«å›¾ç‰‡é€šå¸¸é¥±å’Œåº¦è¾ƒé«˜ï¼‰
        saturation = hsv[:, :, 1].mean() / 255.0
        features["saturation"] = saturation
        
        # è®¡ç®—é¢œè‰²ä¸°å¯Œåº¦ï¼ˆé€šè¿‡ç›´æ–¹å›¾ï¼‰
        hist_h = cv2.calcHist([hsv], [0], None, [180], [0, 180])
        hist_h = hist_h / hist_h.sum()  # å½’ä¸€åŒ–
        color_variety = (hist_h > 0.01).sum() / 180.0
        features["color_variety"] = float(color_variety)
        
        # è¾¹ç¼˜æ£€æµ‹ï¼ˆåŠ¨æ¼«å›¾ç‰‡è¾¹ç¼˜é€šå¸¸æ›´æ¸…æ™°ï¼‰
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        edges = cv2.Canny(gray, 100, 200)
        edge_ratio = edges.mean() / 255.0
        features["edge_ratio"] = edge_ratio
        
        # é¢œè‰²æ•°é‡ï¼ˆåŠ¨æ¼«å›¾ç‰‡é¢œè‰²æ•°é‡ç›¸å¯¹è¾ƒå°‘ä½†è¾¹ç•Œæ¸…æ™°ï¼‰
        small = cv2.resize(image, (64, 64))
        small = (small // 32) * 32  # é‡åŒ–é¢œè‰²
        unique_colors = len(np.unique(small.reshape(-1, 3), axis=0))
        features["unique_colors"] = unique_colors
        
        # åˆ¤æ–­æ˜¯å¦å¯èƒ½æ˜¯åŠ¨æ¼«/å¡é€šé£æ ¼
        is_anime_style = (
            saturation > cls.COLOR_THRESHOLDS["anime_saturation"] and
            edge_ratio > cls.COLOR_THRESHOLDS["anime_edge_ratio"] and
            unique_colors < 500  # åŠ¨æ¼«é€šå¸¸é¢œè‰²æ•°é‡æœ‰é™
        )
        features["is_anime_style"] = bool(is_anime_style)
        
        # è®¡ç®—äº®åº¦ï¼ˆç”¨äºåˆ¤æ–­å®¤å†…å¤–ï¼‰
        brightness = hsv[:, :, 2].mean() / 255.0
        features["brightness"] = float(brightness)
        features["saturation"] = float(saturation)
        features["edge_ratio"] = float(edge_ratio)
        
        return features
    
    @classmethod
    def classify_scene(cls, classifications: list, image_features: dict = None, detected_objects: list = None) -> dict:
        """æ ¹æ®åˆ†ç±»ç»“æœæ¨æ–­åœºæ™¯ç±»å‹"""
        
        scene_scores = {scene: 0.0 for scene in cls.SCENE_TYPES.keys()}
        matched_keywords = []
        
        # åˆ†æåˆ†ç±»ç»“æœ
        for item in classifications:
            class_name = item["class_name"].lower()
            confidence = item["confidence"]
            
            for scene_type, scene_info in cls.SCENE_TYPES.items():
                for keyword in scene_info["keywords"]:
                    if keyword in class_name or class_name in keyword:
                        scene_scores[scene_type] += confidence
                        matched_keywords.append({
                            "keyword": keyword,
                            "class": class_name,
                            "scene": scene_type,
                            "confidence": confidence
                        })
        
        # åˆ†ææ£€æµ‹åˆ°çš„å¯¹è±¡ï¼ˆå¦‚æœæœ‰ï¼‰
        if detected_objects:
            for obj in detected_objects:
                obj_name = obj["class_name"].lower()
                obj_conf = obj["confidence"]
                
                # äººç‰©æ£€æµ‹æƒé‡æ›´é«˜
                if obj_name == "person":
                    scene_scores["portrait"] += obj_conf * 1.5
                
                for scene_type, scene_info in cls.SCENE_TYPES.items():
                    for keyword in scene_info["keywords"]:
                        if keyword in obj_name:
                            scene_scores[scene_type] += obj_conf * 0.8
        
        # å›¾åƒç‰¹å¾åˆ†æåŠ æˆ
        if image_features:
            # åŠ¨æ¼«/å¡é€šé£æ ¼æ£€æµ‹
            if image_features.get("is_anime_style", False):
                scene_scores["art"] += 0.5
            
            # é«˜é¥±å’Œåº¦å¯èƒ½æ˜¯é£Ÿç‰©æˆ–è‰ºæœ¯
            if image_features.get("saturation", 0) > 0.5:
                scene_scores["food"] += 0.1
                scene_scores["art"] += 0.1
        
        # æ‰¾å‡ºå¾—åˆ†æœ€é«˜çš„åœºæ™¯
        best_scene = max(scene_scores, key=scene_scores.get)
        best_score = scene_scores[best_scene]
        
        # å¦‚æœæœ€é«˜åˆ†å¤ªä½ï¼Œæ ‡è®°ä¸ºæœªçŸ¥
        if best_score < 0.1:
            best_scene = "unknown"
        
        scene_info = cls.SCENE_TYPES[best_scene]
        
        # è®¡ç®—æ‰€æœ‰åœºæ™¯çš„ç½®ä¿¡åº¦åˆ†å¸ƒ
        total_score = sum(scene_scores.values()) + 0.001  # é¿å…é™¤é›¶
        scene_distribution = [
            {
                "type": scene,
                "name": cls.SCENE_TYPES[scene]["name"],
                "icon": cls.SCENE_TYPES[scene]["icon"],
                "confidence": score / total_score
            }
            for scene, score in sorted(scene_scores.items(), key=lambda x: -x[1])
            if score > 0
        ][:5]  # åªè¿”å›å‰5ä¸ª
        
        return {
            "primary_scene": {
                "type": best_scene,
                "name": scene_info["name"],
                "icon": scene_info["icon"],
                "description": scene_info["description"],
                "confidence": min(best_score, 1.0)
            },
            "scene_distribution": scene_distribution,
            "matched_keywords": matched_keywords[:10],
            "image_features": {
                "is_anime_style": bool(image_features.get("is_anime_style", False)) if image_features else False,
                "saturation": float(round(image_features.get("saturation", 0), 2)) if image_features else 0.0,
                "brightness": float(round(image_features.get("brightness", 0), 2)) if image_features else 0.0,
            }
        }


# å…¨å±€å®ä¾‹
scene_analyzer = SceneAnalyzer()
